# gpt_bridge.py (Com tratamento de respostas vazias/bloqueadas)

import os
import google.generativeai as genai
from dotenv import load_dotenv
import PIL.Image
import re

# Carrega as vari√°veis de ambiente
load_dotenv()

try:
    api_key = os.getenv("GOOGLE_API_KEY")
    if not api_key:
        print("‚ùå Chave de API do Google (GOOGLE_API_KEY) n√£o encontrada.")
        genai.configure(api_key="CHAVE_INVALIDA")
    else:
        genai.configure(api_key=api_key)
except Exception as e:
    print(f"ü§Ø Erro ao configurar a API do Gemini: {e}")


async def perguntar_ao_gpt(mensagem_usuario):
    """
    Envia um prompt de TEXTO para o modelo Gemini e trata respostas vazias.
    """
    print("üß† Enviando prompt de texto para o Google Gemini...")
    try:
        model = genai.GenerativeModel(
            'gemini-1.5-flash-latest',
            system_instruction="Voc√™ √© a assistente LISA. Responda perguntas de forma direta e clara."
        )
        response = await model.generate_content_async(mensagem_usuario)

        if not response.parts:
            print("‚ö†Ô∏è Resposta do Gemini foi bloqueada ou retornou vazia (provavelmente filtro de seguran√ßa).")
            return "N√£o posso responder a isso."

        print("‚úÖ Resposta de texto recebida do Gemini.")
        return response.text.strip()
    except Exception as e:
        print(f"ü§Ø Erro ao chamar a API do Gemini (texto): {e}")
        return "Desculpe, estou com problemas de conex√£o com minha IA."


async def descrever_imagem(caminho_imagem, prompt_texto):
    """
    Envia uma IMAGEM e um prompt de texto para o Gemini e trata respostas vazias.
    """
    print(f"üñºÔ∏è  Enviando imagem '{caminho_imagem}' para an√°lise do Gemini...")
    try:
        img = PIL.Image.open(caminho_imagem)
        model = genai.GenerativeModel('gemini-1.5-flash-latest')
        response = await model.generate_content_async([prompt_texto, img])

        if not response.parts:
            print("‚ö†Ô∏è An√°lise de imagem do Gemini foi bloqueada ou retornou vazia.")
            return "N√£o consegui processar o conte√∫do desta imagem."

        print("‚úÖ An√°lise de imagem recebida do Gemini.")
        return response.text.strip()
    except FileNotFoundError:
        print(f"‚ùå Erro: Imagem n√£o encontrada em '{caminho_imagem}'")
        return "Desculpe, n√£o consegui encontrar o arquivo de imagem."
    except Exception as e:
        print(f"ü§Ø Erro ao chamar a API do Gemini (imagem): {e}")
        return "Desculpe, n√£o consegui analisar a imagem."


async def gerar_codigo_com_gpt(prompt_usuario: str) -> str:
    """
    Envia um prompt para o Gemini com foco em gerar apenas c√≥digo Python.
    """
    print("ü§ñ Enviando prompt de gera√ß√£o de c√≥digo para o Google Gemini...")
    try:
        model = genai.GenerativeModel(
            'gemini-1.5-flash-latest',
            system_instruction=(
                "Voc√™ √© um assistente de programa√ß√£o especialista em Python. "
                "Sua tarefa √© gerar APENAS o c√≥digo Python funcional que resolve o pedido do usu√°rio. "
                "N√£o inclua explica√ß√µes, coment√°rios desnecess√°rios, ou a palavra 'python' no in√≠cio do c√≥digo. "
                "O c√≥digo deve ser completo e pronto para ser executado."
            )
        )
        response = await model.generate_content_async(f"Crie um script Python que fa√ßa o seguinte: {prompt_usuario}")

        if not response.parts:
            print("‚ö†Ô∏è Gera√ß√£o de c√≥digo bloqueada ou retornou vazia.")
            return None

        codigo_limpo = re.sub(r'^```python\s*|\s*```$', '', response.text.strip(), flags=re.MULTILINE)

        print("‚úÖ C√≥digo recebido do Gemini.")
        return codigo_limpo
    except Exception as e:
        print(f"ü§Ø Erro ao chamar a API do Gemini (c√≥digo): {e}")
        return None


async def alterar_codigo_com_gpt(codigo_anterior: str, pedido_de_alteracao: str) -> str:
    """
    Envia um c√≥digo existente e um pedido de altera√ß√£o para a IA.
    """
    print("ü§ñ Enviando prompt de altera√ß√£o de c√≥digo para o Google Gemini...")
    try:
        model = genai.GenerativeModel(
            'gemini-1.5-flash-latest',
            system_instruction=(
                "Voc√™ √© um assistente de programa√ß√£o especialista em Python. "
                "Sua tarefa √© modificar o c√≥digo Python fornecido de acordo com o pedido do usu√°rio. "
                "Retorne APENAS o c√≥digo Python completo e modificado. "
                "N√£o inclua explica√ß√µes, coment√°rios desnecess√°rios, ou a palavra 'python' no in√≠cio do c√≥digo."
            )
        )
        prompt_completo = (
            f"Aqui est√° um c√≥digo Python:\n\n```python\n{codigo_anterior}\n```\n\n"
            f"Por favor, modifique este c√≥digo para fazer o seguinte: {pedido_de_alteracao}"
        )
        response = await model.generate_content_async(prompt_completo)

        if not response.parts:
            print("‚ö†Ô∏è Altera√ß√£o de c√≥digo bloqueada ou retornou vazia.")
            return None

        codigo_limpo = re.sub(r'^```python\s*|\s*```$', '', response.text.strip(), flags=re.MULTILINE)

        print("‚úÖ C√≥digo alterado recebido do Gemini.")
        return codigo_limpo
    except Exception as e:
        print(f"ü§Ø Erro ao chamar a API do Gemini (altera√ß√£o de c√≥digo): {e}")
        return None